{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDRwxUMkI5Wz"
      },
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4JZt74jGxXE",
        "outputId": "c797277a-341f-44e9-a159-6b6a003bbddf"
      },
      "source": [
        "# Standard script to load GPU\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUS Available: \", len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUS Available:  1\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdu0K2gqAzEi",
        "outputId": "3d6a9610-b650-4ca5-d736-2798190c8d76"
      },
      "source": [
        "data = pd.read_csv('Sentiment.csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]\n",
        "print(data)\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text sentiment\n",
            "0      RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
            "1      RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
            "2      RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
            "3      RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
            "4      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
            "...                                                  ...       ...\n",
            "13866  RT @cappy_yarbrough: Love to see men who will ...  Negative\n",
            "13867  RT @georgehenryw: Who thought Huckabee exceede...  Positive\n",
            "13868  RT @Lrihendry: #TedCruz As President, I will a...  Positive\n",
            "13869  RT @JRehling: #GOPDebate Donald Trump says tha...  Negative\n",
            "13870  RT @Lrihendry: #TedCruz headed into the Presid...  Positive\n",
            "\n",
            "[13871 rows x 2 columns]\n",
            "                                                    text sentiment\n",
            "0      rt nancyleegrahn how did everyone feel about t...   Neutral\n",
            "1      rt scottwalker didnt catch the full gopdebate ...  Positive\n",
            "2      rt tjmshow no mention of tamir rice and the go...   Neutral\n",
            "3      rt robgeorge that carly fiorina is trending  h...  Positive\n",
            "4      rt danscavino gopdebate w realdonaldtrump deli...  Positive\n",
            "...                                                  ...       ...\n",
            "13866  rt cappy_yarbrough love to see men who will ne...  Negative\n",
            "13867  rt georgehenryw who thought huckabee exceeded ...  Positive\n",
            "13868  rt lrihendry tedcruz as president i will alway...  Positive\n",
            "13869  rt jrehling gopdebate donald trump says that h...  Negative\n",
            "13870  rt lrihendry tedcruz headed into the president...  Positive\n",
            "\n",
            "[13871 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUmQgDR8A1c2",
        "outputId": "79515c27-e053-4a8a-87e2-233eab072e09"
      },
      "source": [
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')\n",
        "print(data)\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "X = pad_sequences(X)\n",
        "\n",
        "print(X[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text sentiment\n",
            "0        nancyleegrahn how did everyone feel about th...   Neutral\n",
            "1        scottwalker didnt catch the full gopdebate l...  Positive\n",
            "2        tjmshow no mention of tamir rice and the gop...   Neutral\n",
            "3        robgeorge that carly fiorina is trending  ho...  Positive\n",
            "4        danscavino gopdebate w realdonaldtrump deliv...  Positive\n",
            "...                                                  ...       ...\n",
            "13866    cappy_yarbrough love to see men who will nev...  Negative\n",
            "13867    georgehenryw who thought huckabee exceeded t...  Positive\n",
            "13868    lrihendry tedcruz as president i will always...  Positive\n",
            "13869    jrehling gopdebate donald trump says that he...  Negative\n",
            "13870    lrihendry tedcruz headed into the presidenti...  Positive\n",
            "\n",
            "[13871 rows x 2 columns]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0   52   78  341  456   22    2  420  365   95   29   51 1039    1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXr9dJ-BA5XI"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "def createmodel():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "    return model\n",
        "# print(model.summary())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf6THGAxA7E6",
        "outputId": "54014659-9e14-4f8c-ce31-1093feee3f99"
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "# Find how Hot encoding \n",
        "print(y[1], \" Is positive\")\n",
        "print(y[0], \" Is neutral\")\n",
        "print(y[13866], \" Is negative\")\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 1.]  Is positive\n",
            "[0. 1. 0.]  Is neutral\n",
            "[1. 0. 0.]  Is negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3L-o-6CqtmV"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "model = KerasClassifier(build_fn=createmodel, verbose=0)\n",
        "batch_size= [10, 20, 40]\n",
        "epochs = [1, 2, 3]\n",
        "param_grid= dict(batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt7LOzOSquD4",
        "outputId": "dd72c08a-8b71-40c6-838c-b4591b712a4b"
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "  grid= GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "  grid_result= grid.fit(X_train, Y_train)\n",
        "  # summarize results\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Best: 0.680189 using {'batch_size': 40, 'epochs': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cODu1NqnA9V9",
        "outputId": "a378bf7c-ef35-4a5c-c801-4cb9211ea88e"
      },
      "source": [
        "  batch_size = 40\n",
        "  epoch = 2\n",
        "  with tf.device('/gpu:0'):\n",
        "    model = createmodel()\n",
        "    model.fit(X_train, Y_train, epochs = epoch, batch_size=batch_size, verbose = 2)\n",
        "    score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
        "    print(score)\n",
        "    print(acc)\n",
        "    print(model.metrics_names)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_46 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/2\n",
            "233/233 - 25s - loss: 0.8280 - accuracy: 0.6437\n",
            "Epoch 2/2\n",
            "233/233 - 23s - loss: 0.6847 - accuracy: 0.7096\n",
            "115/115 - 1s - loss: 0.7408 - accuracy: 0.6861\n",
            "0.7407616376876831\n",
            "0.6861074566841125\n",
            "['loss', 'accuracy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq73T-O7TOEL"
      },
      "source": [
        "model: model.save('model.h5')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrBhVyoZTjk2",
        "outputId": "1f91ff16-9be0-4e1a-f995-deeb987940e4"
      },
      "source": [
        "# Import the saved model\n",
        "saved = load_model('model.h5')\n",
        "# Numpy for manipulatation\n",
        "import numpy as np\n",
        "\n",
        "# create the sample tweet and subject it to the same preprocessing\n",
        "tweet = [\"@realDonaldTrump: A lot of good things are happening. We are respected again throughout the world, and that's a great thing\"]\n",
        "tweet[0] = tweet[0].lower()\n",
        "tweet[0] = re.sub('[^a-zA-z0-9\\s]', '', tweet[0])\n",
        "\n",
        "# Check if string is prepped\n",
        "print(tweet, \"\\n\")\n",
        "\n",
        "# Tokenize string\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(tweet)\n",
        "X = tokenizer.texts_to_sequences(tweet)\n",
        "\n",
        "X = pad_sequences(X, maxlen=28)\n",
        "\n",
        "# Show the output neurons\n",
        "print(saved(X), \"\\n\")\n",
        "\n",
        "# Display the prediciton\n",
        "result = np.argmax(saved(X))\n",
        "\n",
        "if(result == 0):\n",
        "  print(\"Sentence is Negative\")\n",
        "elif(result == 1):\n",
        "  print(\"Sentence is Neutral\")\n",
        "elif(result == 2):\n",
        "  print(\"Sentence is Positive\")\n",
        "\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "['realdonaldtrump a lot of good things are happening we are respected again throughout the world and thats a great thing'] \n",
            "\n",
            "tf.Tensor([[0.88424104 0.07245608 0.04330288]], shape=(1, 3), dtype=float32) \n",
            "\n",
            "Sentence is Negative\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}