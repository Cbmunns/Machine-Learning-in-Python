{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDRwxUMkI5Wz"
      },
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdu0K2gqAzEi",
        "outputId": "f8d4e5ac-355f-47dd-edeb-7eb795696a1b"
      },
      "source": [
        "data = pd.read_csv('Sentiment.csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]\n",
        "print(data)\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text sentiment\n",
            "0      RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
            "1      RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
            "2      RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
            "3      RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
            "4      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
            "...                                                  ...       ...\n",
            "13866  RT @cappy_yarbrough: Love to see men who will ...  Negative\n",
            "13867  RT @georgehenryw: Who thought Huckabee exceede...  Positive\n",
            "13868  RT @Lrihendry: #TedCruz As President, I will a...  Positive\n",
            "13869  RT @JRehling: #GOPDebate Donald Trump says tha...  Negative\n",
            "13870  RT @Lrihendry: #TedCruz headed into the Presid...  Positive\n",
            "\n",
            "[13871 rows x 2 columns]\n",
            "                                                    text sentiment\n",
            "0      rt nancyleegrahn how did everyone feel about t...   Neutral\n",
            "1      rt scottwalker didnt catch the full gopdebate ...  Positive\n",
            "2      rt tjmshow no mention of tamir rice and the go...   Neutral\n",
            "3      rt robgeorge that carly fiorina is trending  h...  Positive\n",
            "4      rt danscavino gopdebate w realdonaldtrump deli...  Positive\n",
            "...                                                  ...       ...\n",
            "13866  rt cappy_yarbrough love to see men who will ne...  Negative\n",
            "13867  rt georgehenryw who thought huckabee exceeded ...  Positive\n",
            "13868  rt lrihendry tedcruz as president i will alway...  Positive\n",
            "13869  rt jrehling gopdebate donald trump says that h...  Negative\n",
            "13870  rt lrihendry tedcruz headed into the president...  Positive\n",
            "\n",
            "[13871 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUmQgDR8A1c2",
        "outputId": "90f28e8b-6beb-4b12-dada-bcda67cf1665"
      },
      "source": [
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')\n",
        "print(data)\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "X = pad_sequences(X)\n",
        "\n",
        "print(X[0])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text sentiment\n",
            "0        nancyleegrahn how did everyone feel about th...   Neutral\n",
            "1        scottwalker didnt catch the full gopdebate l...  Positive\n",
            "2        tjmshow no mention of tamir rice and the gop...   Neutral\n",
            "3        robgeorge that carly fiorina is trending  ho...  Positive\n",
            "4        danscavino gopdebate w realdonaldtrump deliv...  Positive\n",
            "...                                                  ...       ...\n",
            "13866    cappy_yarbrough love to see men who will nev...  Negative\n",
            "13867    georgehenryw who thought huckabee exceeded t...  Positive\n",
            "13868    lrihendry tedcruz as president i will always...  Positive\n",
            "13869    jrehling gopdebate donald trump says that he...  Negative\n",
            "13870    lrihendry tedcruz headed into the presidenti...  Positive\n",
            "\n",
            "[13871 rows x 2 columns]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0   52   78  341  456   22    2  420  365   95   29   51 1039    1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXr9dJ-BA5XI"
      },
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "def createmodel():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "    return model\n",
        "# print(model.summary())"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf6THGAxA7E6",
        "outputId": "a05709b5-6639-4601-f570-5ea0030ff941"
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "print(y[1], \" Is positive\")\n",
        "print(y[0], \" Is neutral\")\n",
        "print(y[13866], \" Is negative\")\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 1.]  Is positive\n",
            "[0. 1. 0.]  Is neutral\n",
            "[1. 0. 0.]  Is negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cODu1NqnA9V9",
        "outputId": "b911c56e-4c8c-42cb-9153-7e858f10297f"
      },
      "source": [
        "  batch_size = 32\n",
        "  model = createmodel()\n",
        "  model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2)\n",
        "  score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
        "  print(score)\n",
        "  print(acc)\n",
        "  print(model.metrics_names)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "291/291 - 32s - loss: 0.8299 - accuracy: 0.6505\n",
            "144/144 - 1s - loss: 0.7567 - accuracy: 0.6734\n",
            "0.7567443251609802\n",
            "0.6734381914138794\n",
            "['loss', 'accuracy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq73T-O7TOEL"
      },
      "source": [
        "model: model.save('model.h5')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrBhVyoZTjk2",
        "outputId": "1f91ff16-9be0-4e1a-f995-deeb987940e4"
      },
      "source": [
        "# Import the saved model\n",
        "saved = load_model('model.h5')\n",
        "# Numpy for manipulatation\n",
        "import numpy as np\n",
        "\n",
        "# create the sample tweet and subject it to the same preprocessing\n",
        "tweet = [\"@realDonaldTrump: A lot of good things are happening. We are respected again throughout the world, and that's a great thing\"]\n",
        "tweet[0] = tweet[0].lower()\n",
        "tweet[0] = re.sub('[^a-zA-z0-9\\s]', '', tweet[0])\n",
        "\n",
        "# Check if string is prepped\n",
        "print(tweet, \"\\n\")\n",
        "\n",
        "# Tokenize string\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(tweet)\n",
        "X = tokenizer.texts_to_sequences(tweet)\n",
        "\n",
        "X = pad_sequences(X, maxlen=28)\n",
        "\n",
        "# Show the output neurons\n",
        "print(saved(X), \"\\n\")\n",
        "\n",
        "# Display the prediciton\n",
        "result = np.argmax(saved(X))\n",
        "\n",
        "if(result == 0):\n",
        "  print(\"Sentence is Negative\")\n",
        "elif(result == 1):\n",
        "  print(\"Sentence is Neutral\")\n",
        "elif(result == 2):\n",
        "  print(\"Sentence is Positive\")\n",
        "\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "['realdonaldtrump a lot of good things are happening we are respected again throughout the world and thats a great thing'] \n",
            "\n",
            "tf.Tensor([[0.88424104 0.07245608 0.04330288]], shape=(1, 3), dtype=float32) \n",
            "\n",
            "Sentence is Negative\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}